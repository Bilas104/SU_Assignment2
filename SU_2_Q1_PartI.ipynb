{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part I: VoxCeleb Dataset Preparation"
      ],
      "metadata": {
        "id": "PHa4hvHwWyqV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5Le-IwOTWNCU"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import normalize\n",
        "from transformers import Wav2Vec2FeatureExtractor, WavLMModel, HubertModel, Wav2Vec2Model, UniSpeechSatModel\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import soundfile as sf\n",
        "import pickle\n",
        "import shutil\n",
        "import zipfile\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1Y_3GV9ZHh9",
        "outputId": "af6111c2-ac50-43ee-dd1c-613efaf01fac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpdsCMu6W5Ze",
        "outputId": "0009746c-d43e-48d0-8607-51eb35a8e90d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/SU_Assignment_2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fl32ie5fKto",
        "outputId": "16a09fe7-c1bd-4ff3-81a9-731842889a57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SU_Assignment_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9zQb0pkfR2t",
        "outputId": "4fcdc8bc-88bf-4c3f-ac70-6644ca5e9567"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mvox1\u001b[0m/  \u001b[01;34mvox2\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls vox1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBg1OyWLecTS",
        "outputId": "a251f254-2575-4f20-fbbd-aeb66be0804b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vox1_test_wav.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/voxceleb_data/vox1', exist_ok = True)\n",
        "os.makedirs('/content/voxceleb_data/vox2_aac', exist_ok = True)\n",
        "os.makedirs('/content/voxceleb_data/vox2_txt', exist_ok = True)"
      ],
      "metadata": {
        "id": "rTCJ1eGGan_8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder = '/content/drive/MyDrive/SU_Assignment_2'\n",
        "shared_vox1 = f'{folder}/vox1/vox1_test_wav.zip'\n",
        "shared_vox2_audio = f'{folder}/vox2/vox2_test_aac-002.zip'\n",
        "shared_vox2_txt = f'{folder}/vox2/vox2_test_txt.zip'"
      ],
      "metadata": {
        "id": "nw9ephsiehwU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"vox1_test_wav.zip exists: {os.path.exists(shared_vox1)}\")\n",
        "print(f\"vox2_test_aac-002.zip exists: {os.path.exists(shared_vox2_audio)}\")\n",
        "print(f\"vox2_test_txt.zip exists: {os.path.exists(shared_vox2_txt)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBeO7qmmflDG",
        "outputId": "9d1ed738-277d-420b-b1bb-999b8743d47c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vox1_test_wav.zip exists: True\n",
            "vox2_test_aac-002.zip exists: True\n",
            "vox2_test_txt.zip exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy files from Drive to local Colab VM\n",
        "shutil.copy(shared_vox1, \"/content/\")\n",
        "shutil.copy(shared_vox2_audio, \"/content/\")\n",
        "shutil.copy(shared_vox2_txt, \"/content/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "I-1EiGWEbzyv",
        "outputId": "392caae0-bcda-4aaf-b922-1eff5ea12b70"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/vox2_test_txt.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract zip files with full paths\n",
        "zips_and_targets = {\n",
        "    \"/content/vox1_test_wav.zip\": \"/content/voxceleb_data/vox1\",\n",
        "    \"/content/vox2_test_aac-002.zip\": \"/content/voxceleb_data/vox2_aac\",\n",
        "    \"/content/vox2_test_txt.zip\": \"/content/voxceleb_data/vox2_txt\"\n",
        "}\n",
        "\n",
        "for zip_file, target_dir in zips_and_targets.items():\n",
        "    print(f\"Extracting {zip_file} to {target_dir}...\")\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(target_dir)\n",
        "    print(f\"Done extracting {zip_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVJPH-K7gXwP",
        "outputId": "24f5497b-dc8a-4e35-ea28-22608f93db04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/vox1_test_wav.zip to /content/voxceleb_data/vox1...\n",
            "Done extracting /content/vox1_test_wav.zip\n",
            "Extracting /content/vox2_test_aac-002.zip to /content/voxceleb_data/vox2_aac...\n",
            "Done extracting /content/vox2_test_aac-002.zip\n",
            "Extracting /content/vox2_test_txt.zip to /content/voxceleb_data/vox2_txt...\n",
            "Done extracting /content/vox2_test_txt.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert VoxCeleb2 AAC files to WAV format\n",
        "aac_root = \"/content/voxceleb_data/vox2_aac/aac\"\n",
        "wav_root = \"/content/voxceleb_data/vox2_wav\"\n",
        "os.makedirs(wav_root, exist_ok=True)\n",
        "\n",
        "# Get speaker directories\n",
        "speaker_dirs = sorted(os.listdir(aac_root))[:118]\n",
        "print(f\"Total speakers (VoxCeleb2): {len(speaker_dirs)}\")\n",
        "\n",
        "for speaker in tqdm(speaker_dirs, desc=\"Converting AAC to WAV\"):\n",
        "    speaker_path = os.path.join(aac_root, speaker)\n",
        "    for root, _, files in os.walk(speaker_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".m4a\"):\n",
        "                m4a_path = os.path.join(root, file)\n",
        "                relative_path = os.path.relpath(m4a_path, aac_root)\n",
        "                wav_path = os.path.join(wav_root, relative_path.replace(\".m4a\", \".wav\"))\n",
        "                os.makedirs(os.path.dirname(wav_path), exist_ok=True)\n",
        "                try:\n",
        "                    waveform, sr = torchaudio.load(m4a_path)\n",
        "                    torchaudio.save(wav_path, waveform, sr)\n",
        "                except Exception as e:\n",
        "                    print(f\"Skipped {m4a_path} — {e}\")\n",
        "print(\"Finished converting VoxCeleb2 AAC files to WAV.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IxzKob3hRH8",
        "outputId": "40359a37-27b6-415e-b075-b5d207729257"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total speakers (VoxCeleb2): 118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting AAC to WAV: 100%|██████████| 118/118 [05:57<00:00,  3.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished converting VoxCeleb2 AAC files to WAV.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio(path, target_sr=16000):\n",
        "    try:\n",
        "        waveform, sample_rate = torchaudio.load(path)\n",
        "        if waveform.shape[0] > 1:  # Convert stereo to mono if needed\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "        if sample_rate != target_sr:\n",
        "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sr)\n",
        "            waveform = resampler(waveform)\n",
        "        return waveform.squeeze(0)  # Return as torch.Tensor\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {path}: {e}\")\n",
        "        # Fallback to soundfile if torchaudio fails\n",
        "        audio, sr = sf.read(path)\n",
        "        if sr != target_sr:\n",
        "            raise ValueError(\"Resampling not implemented for fallback method.\")\n",
        "        return torch.tensor(audio, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "kxCNNp5-jeR1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VoxCeleb2Dataset(Dataset):\n",
        "    def __init__(self, root_dir, identity_list, max_samples_per_identity=20, sample_rate=16000):\n",
        "        self.sample_rate = sample_rate\n",
        "        self.samples = []\n",
        "        self.identity_map = {identity: idx for idx, identity in enumerate(sorted(identity_list))}\n",
        "\n",
        "        for identity in tqdm(sorted(identity_list), desc=\"Loading dataset\"):\n",
        "            identity_path = os.path.join(root_dir, identity)\n",
        "            files = []\n",
        "            for root, _, filenames in os.walk(identity_path):\n",
        "                for file in filenames:\n",
        "                    if file.endswith('.wav'):\n",
        "                        files.append(os.path.join(root, file))\n",
        "\n",
        "            # Taking a subset of files for each identity\n",
        "            files = sorted(files)[:max_samples_per_identity]\n",
        "\n",
        "            for file_path in files:\n",
        "                self.samples.append((file_path, self.identity_map[identity]))\n",
        "\n",
        "        print(f\"Dataset created with {len(self.samples)} samples across {len(identity_list)} speakers\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        waveform = load_audio(path, target_sr=self.sample_rate)\n",
        "        # Normalize the waveform\n",
        "        waveform = waveform / (torch.max(torch.abs(waveform)) + 1e-8)\n",
        "        return waveform, label"
      ],
      "metadata": {
        "id": "Qo4pO3jIjloz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    waveforms, labels = zip(*batch)\n",
        "    # Setting maximum audio length (3 seconds at 16kHz)\n",
        "    MAX_AUDIO_LENGTH = 16000 * 3\n",
        "\n",
        "    # Clip or pad waveforms\n",
        "    clipped_waveforms = [w[:MAX_AUDIO_LENGTH] if w.shape[0] > MAX_AUDIO_LENGTH else w for w in waveforms]\n",
        "    max_len = max(w.shape[0] for w in clipped_waveforms)\n",
        "\n",
        "    # Pad all waveforms to the same length\n",
        "    padded = [F.pad(w, (0, max_len - w.shape[0])) for w in clipped_waveforms]\n",
        "\n",
        "    return torch.stack(padded), torch.tensor(labels)"
      ],
      "metadata": {
        "id": "4_RZElC1kDJi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_verification_pairs(veri_txt_path, vox1_root):\n",
        "    pairs = []\n",
        "    with open(veri_txt_path, 'r') as f:\n",
        "        for line in tqdm(f, desc=\"Preparing verification pairs\"):\n",
        "            parts = line.strip().split()\n",
        "            label = int(parts[0])\n",
        "            path1 = os.path.join(vox1_root, parts[1])\n",
        "            path2 = os.path.join(vox1_root, parts[2])\n",
        "\n",
        "            # Only add valid pairs where both files exist\n",
        "            if os.path.exists(path1) and os.path.exists(path2):\n",
        "                pairs.append((path1, path2, label))\n",
        "\n",
        "    print(f\"Prepared {len(pairs)} verification pairs\")\n",
        "    return pairs"
      ],
      "metadata": {
        "id": "0rEbM0fWkKaZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_verification_list():\n",
        "    !wget https://mm.kaist.ac.kr/datasets/voxceleb/meta/veri_test.txt -O /content/veri_test.txt\n",
        "    return \"/content/veri_test.txt\"\n",
        "\n",
        "# Download verification list\n",
        "veri_txt_path = download_verification_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIYJAbdLqwUe",
        "outputId": "7a1f0ddc-3080-4e19-cbdc-0ae40325408f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-06 02:44:45--  https://mm.kaist.ac.kr/datasets/voxceleb/meta/veri_test.txt\n",
            "Resolving mm.kaist.ac.kr (mm.kaist.ac.kr)... 143.248.39.47\n",
            "Connecting to mm.kaist.ac.kr (mm.kaist.ac.kr)|143.248.39.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2338640 (2.2M) [text/plain]\n",
            "Saving to: ‘/content/veri_test.txt’\n",
            "\n",
            "/content/veri_test. 100%[===================>]   2.23M   468KB/s    in 5.1s    \n",
            "\n",
            "2025-04-06 02:44:51 (451 KB/s) - ‘/content/veri_test.txt’ saved [2338640/2338640]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset_splits(wav_root):\n",
        "    # Get all speaker identities and sort them\n",
        "    all_identities = sorted(os.listdir(wav_root))\n",
        "\n",
        "    train_identities = all_identities[:100]  # First 100 identities for training\n",
        "    test_identities = all_identities[100:118]  # Next 18 identities for testing\n",
        "\n",
        "    print(f\"Total identities: {len(all_identities)}\")\n",
        "    print(f\"Training identities: {len(train_identities)}\")\n",
        "    print(f\"Testing identities: {len(test_identities)}\")\n",
        "\n",
        "    return train_identities, test_identities\n",
        "\n",
        "# Prepare dataset splits\n",
        "train_identities, test_identities = prepare_dataset_splits(wav_root)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4DzrsaCpJfi",
        "outputId": "f3e703f5-b51f-44ce-f99b-e3a3acd90604"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total identities: 118\n",
            "Training identities: 100\n",
            "Testing identities: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_datasets(wav_root, train_identities, test_identities):\n",
        "    # Create dataset instances\n",
        "    train_dataset = VoxCeleb2Dataset(\n",
        "        root_dir=wav_root,\n",
        "        identity_list=train_identities,\n",
        "        max_samples_per_identity=20\n",
        "    )\n",
        "\n",
        "    test_dataset = VoxCeleb2Dataset(\n",
        "        root_dir=wav_root,\n",
        "        identity_list=test_identities,\n",
        "        max_samples_per_identity=20\n",
        "    )\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "# Create datasets\n",
        "train_dataset, test_dataset = create_datasets(wav_root, train_identities, test_identities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x299yZ2KpNkw",
        "outputId": "a963a6b6-3fff-4bbf-e4c9-11ce461ea6de"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 100/100 [00:00<00:00, 771.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created with 2000 samples across 100 speakers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 18/18 [00:00<00:00, 736.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created with 360 samples across 18 speakers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loaders(train_dataset, test_dataset, batch_size=8):\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    print(f\"Created data loaders - Training: {len(train_loader)}, Testing: {len(test_loader)}\")\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# Create data loaders\n",
        "train_loader, test_loader = create_data_loaders(train_dataset, test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ouUS1ANrFxf",
        "outputId": "8e80944c-2aac-4edb-a457-7896d19981d8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created data loaders - Training: 250, Testing: 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data for multi-speaker scenarios\n",
        "def prepare_multispeaker_data(wav_root, train_identities):\n",
        "    ms_train_identities = train_identities[:50]  # First 50 for multi-speaker training\n",
        "    ms_test_identities = train_identities[50:100]  # Next 50 for multi-speaker testing\n",
        "\n",
        "    print(f\"Multi-speaker training identities: {len(ms_train_identities)}\")\n",
        "    print(f\"Multi-speaker testing identities: {len(ms_test_identities)}\")\n",
        "\n",
        "    # Create multi-speaker datasets\n",
        "    ms_train_dataset = VoxCeleb2Dataset(\n",
        "        root_dir=wav_root,\n",
        "        identity_list=ms_train_identities,\n",
        "        max_samples_per_identity=20\n",
        "    )\n",
        "\n",
        "    ms_test_dataset = VoxCeleb2Dataset(\n",
        "        root_dir=wav_root,\n",
        "        identity_list=ms_test_identities,\n",
        "        max_samples_per_identity=20\n",
        "    )\n",
        "\n",
        "    print(f\"Multi-speaker training samples: {len(ms_train_dataset)}\")\n",
        "    print(f\"Multi-speaker testing samples: {len(ms_test_dataset)}\")\n",
        "\n",
        "    return ms_train_dataset, ms_test_dataset, ms_train_identities, ms_test_identities\n",
        "\n",
        "# Prepare multi-speaker data\n",
        "ms_train_dataset, ms_test_dataset, ms_train_identities, ms_test_identities = prepare_multispeaker_data(wav_root, train_identities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agBv0AD9rPaN",
        "outputId": "afa0895c-8462-451a-d180-474a608527bb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-speaker training identities: 50\n",
            "Multi-speaker testing identities: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 50/50 [00:00<00:00, 888.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created with 1000 samples across 50 speakers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 50/50 [00:00<00:00, 813.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created with 1000 samples across 50 speakers\n",
            "Multi-speaker training samples: 1000\n",
            "Multi-speaker testing samples: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_verification_data(veri_txt_path):\n",
        "    vox1_wav_root = \"/content/voxceleb_data/vox1/wav\"\n",
        "    verification_pairs = prepare_verification_pairs(veri_txt_path, vox1_wav_root)\n",
        "    return verification_pairs, vox1_wav_root\n",
        "\n",
        "# Prepare verification data\n",
        "verification_pairs, vox1_wav_root = prepare_verification_data(veri_txt_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di3VRaMtrVtU",
        "outputId": "23fe1aa0-f62a-47ac-ada8-0806a3166c39"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preparing verification pairs: 37720it [00:00, 113016.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared 37720 verification pairs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_processed_data(wav_root, vox1_wav_root, veri_txt_path, train_identities, test_identities,\n",
        "                        ms_train_identities, ms_test_identities, train_dataset, test_dataset,\n",
        "                        ms_train_dataset, ms_test_dataset, verification_pairs):\n",
        "    os.makedirs('/content/processed_data', exist_ok=True)\n",
        "\n",
        "    # Save dataset information\n",
        "    data_info = {\n",
        "        'vox2_wav_root': wav_root,\n",
        "        'vox1_wav_root': vox1_wav_root,\n",
        "        'veri_txt_path': veri_txt_path,\n",
        "        'train_identities': train_identities,\n",
        "        'test_identities': test_identities,\n",
        "        'ms_train_identities': ms_train_identities,\n",
        "        'ms_test_identities': ms_test_identities,\n",
        "        'train_samples': [(sample[0], sample[1]) for sample in train_dataset.samples],\n",
        "        'test_samples': [(sample[0], sample[1]) for sample in test_dataset.samples],\n",
        "        'ms_train_samples': [(sample[0], sample[1]) for sample in ms_train_dataset.samples],\n",
        "        'ms_test_samples': [(sample[0], sample[1]) for sample in ms_test_dataset.samples],\n",
        "        'verification_pairs': verification_pairs\n",
        "    }\n",
        "\n",
        "    with open('/content/processed_data/voxceleb_data_info.pkl', 'wb') as f:\n",
        "        pickle.dump(data_info, f)\n",
        "\n",
        "    print(\"Saved dataset information to /content/processed_data/voxceleb_data_info.pkl\")\n",
        "\n",
        "# Save processed data\n",
        "save_processed_data(wav_root, vox1_wav_root, veri_txt_path, train_identities, test_identities,\n",
        "                   ms_train_identities, ms_test_identities, train_dataset, test_dataset,\n",
        "                   ms_train_dataset, ms_test_dataset, verification_pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmqy5yKxrgqO",
        "outputId": "98a5cf17-544a-46dc-ef81-30dfcdbbf72b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved dataset information to /content/processed_data/voxceleb_data_info.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/processed_data/voxceleb_data_info.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ULbUBrxvxo-E",
        "outputId": "4e568e04-4eac-4678-ae7e-7c87b5c2270a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6af44891-de14-4704-ba95-7ff6fe31c636\", \"voxceleb_data_info.pkl\", 5278058)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}